{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 3 notebook - pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "This workbook contains my results for the assignment as specified below. I'll start, however, with a few pandas exercises from the DataCamp source:\n",
    "\n",
    "- [chapter 1 from _Manipulating DataFrames with pandas_](http://bit.ly/2ftzLk0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "    Import numpy using the standard alias np.\n",
    "    Assign the numerical values in the DataFrame df to an array np_vals using the attribute values.\n",
    "    Pass np_vals into the NumPy method log10() and store the results in np_vals_log10.\n",
    "    Pass the entire df DataFrame into the NumPy method log10() and store the results in df_log10.\n",
    "    Call print() and type() on both df_vals_log10 and df_log10, and compare. This has been done for you.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import numpy\n",
    "import numpy as np\n",
    "\n",
    "# Create array of DataFrame values: np_vals\n",
    "np_vals = np.array(df.values)\n",
    "\n",
    "# Create new array of base 10 logarithm values: np_vals_log10\n",
    "np_vals_log10 = np.log10(np_vals)\n",
    "\n",
    "# Create array of new DataFrame by passing df to np.log10(): df_log10\n",
    "df_log10 = np.log10(df)\n",
    "\n",
    "# Print original and new data containers\n",
    "print(type(np_vals), type(np_vals_log10))\n",
    "print(type(df), type(df_log10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "    Zip the 2 lists list_keys and list_values together into one list of (key, value) tuples. Be sure to convert the zip object into a list, and store the result in zipped.\n",
    "    Inspect the contents of zipped using print(). This has been done for you.\n",
    "    Construct a dictionary using zipped. Store the result as data.\n",
    "    Construct a DataFrame using the dictionary. Store the result as df.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Zip the 2 lists together into one list of (key,value) tuples: zipped\n",
    "zipped = list(zip(list_keys, list_values))\n",
    "\n",
    "# Inspect the list using print()\n",
    "print(zipped)\n",
    "\n",
    "# Build a dictionary with the zipped list: data\n",
    "data = dict(zipped)\n",
    "\n",
    "# Build and inspect a DataFrame from the dictionary: df\n",
    "df = pd.DataFrame(data)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "    Create a list of new column labels with 'year', 'artist', 'song', 'chart weeks', and assign it to list_labels.\n",
    "    Assign your list of labels to df.columns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Build a list of labels: list_labels\n",
    "list_labels = ['year', 'artist','song','chart weeks']\n",
    "\n",
    "# Assign the list of labels to the columns attribute: df.columns\n",
    "df.columns = list_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "    Make a string object with the value 'PA' and assign it to state.\n",
    "    Construct a dictionary with 2 key:value pairs: 'state':state and 'city':cities.\n",
    "    Construct a pandas DataFrame from the dictionary you created and assign it to df.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make a string with the value 'PA': state\n",
    "state = 'PA'\n",
    "\n",
    "# Construct a dictionary: data\n",
    "data = {'state':state, 'city':cities}\n",
    "\n",
    "# Construct a DataFrame from dictionary data: df\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Print the DataFrame\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "    Use pd.read_csv() with the string 'world_population.csv' to read the CSV file into a DataFrame and assign it to df1.\n",
    "    Create a list of new column labels - 'year', 'population' - and assign it to the variable new_labels.\n",
    "    Reread the same file, again using pd.read_csv(), but this time, add the keyword arguments header=0 and names=new_labels. Assign the resulting DataFrame to df2.\n",
    "    Print both the df1 and df2 DataFrames to see the change in column names. This has already been done for you.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read in the file: df1\n",
    "df1 = pd.read_csv('world_population.csv')\n",
    "\n",
    "# Create a list of the new column labels: new_labels\n",
    "new_labels = ['year','population']\n",
    "\n",
    "# Read in the file, specifying the header and names parameters: df2\n",
    "df2 = pd.read_csv('world_population.csv', header=0, names=new_labels)\n",
    "\n",
    "# Print both the DataFrames\n",
    "print(df1)\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "    Use pd.read_csv() without using any keyword arguments to read file_messy into a pandas DataFrame df1.\n",
    "    Use .head() to print the first 5 rows of df1 and see how messy it is. Do this in the IPython Shell first so you can see how modifying read_csv() can clean up this mess.\n",
    "    Using the keyword arguments delimiter=' ', header=3 and comment='#', use pd.read_csv() again to read file_messy into a new DataFrame df2.\n",
    "    Print the output of df2.head() to verify the file was read correctly.\n",
    "    Use the DataFrame method .to_csv() to save the DataFrame df2 to the variable file_clean. Be sure to specify index=False.\n",
    "    Use the DataFrame method .to_excel() to save the DataFrame df2 to the file 'file_clean.xlsx'. Again, remember to specify index=False.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read the raw file as-is: df1\n",
    "df1 = pd.read_csv(file_messy)\n",
    "\n",
    "# Print the output of df1.head()\n",
    "print(df1.head())\n",
    "\n",
    "# Read in the file with the correct parameters: df2\n",
    "df2 = pd.read_csv(file_messy, delimiter=' ', header=3, comment='#')\n",
    "\n",
    "# Print the output of df2.head()\n",
    "print(df2.head())\n",
    "\n",
    "# Save the cleaned up DataFrame to a CSV file without the index\n",
    "df2.to_csv(file_clean, index=False)\n",
    "\n",
    "# Save the cleaned up DataFrame to an excel file without the index\n",
    "df2.to_excel('file_clean.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "    Create the plot with the DataFrame method df.plot(). Specify a color of 'red'.\n",
    "        Note: c and color are interchangeable as parameters here, but we ask you to be explicit and specify color.\n",
    "    Use plt.title() to give the plot a title of 'Temperature in Austin'.\n",
    "    Use plt.xlabel() to give the plot an x-axis label of 'Hours since midnight August 1, 2010'.\n",
    "    Use plt.ylabel() to give the plot a y-axis label of 'Temperature (degrees F)'.\n",
    "    Finally, display the plot using plt.show().\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a plot with color='red'\n",
    "df.plot(color='red')\n",
    "\n",
    "# Add a title\n",
    "plt.title('Temperature in Austin')\n",
    "\n",
    "# Specify the x-axis label\n",
    "plt.xlabel('Hours since midnight August 1, 2010')\n",
    "\n",
    "# Specify the y-axis label\n",
    "plt.ylabel('Temperature (degrees F)')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "    Plot all columns together on one figure by calling df.plot(), and noting the vertical scaling problem.\n",
    "    Plot all columns as subplots. To do so, you need to specify subplots=True inside .plot().\n",
    "    Plot a single column of dew point data. To do this, define a column list containing a single column name 'Dew Point (deg F)', and call df[column_list1].plot().\n",
    "    Plot two columns of data, 'Temperature (deg F)' and 'Dew Point (deg F)'. To do this, define a list containing those column names and pass it into df[], as df[column_list2].plot().\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot all columns (default)\n",
    "df.plot()\n",
    "plt.show()\n",
    "\n",
    "# Plot all columns as subplots\n",
    "df.plot(subplots=True)\n",
    "plt.show()\n",
    "\n",
    "# Plot just the Dew Point data\n",
    "column_list1 = ['Dew Point (deg F)']\n",
    "df[column_list1].plot()\n",
    "plt.show()\n",
    "\n",
    "# Plot the Dew Point and Temperature data, but not the Pressure data\n",
    "column_list2 = ['Temperature (deg F)','Dew Point (deg F)']\n",
    "df[column_list2].plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment - Using pandas on my home brew data set\n",
    "\n",
    "### Introduction\n",
    "\n",
    "This assignment is an analysis exercise. It is not as much about the meaning of the analysis you will conduct as it is on the demonstration of common functionality you will use when doing data analysis with pandas. So first an for all it is a demonstration of your pandas skills.\n",
    "\n",
    "### Step 1: data set construction\n",
    "\n",
    "Construct an artificial dataset using either Excel, Google Sheets or numpy. Your constructed dataset has at least:\n",
    "\n",
    "1. 100 rows (measurements/events)\n",
    "1. 4 columns (variables)\n",
    "1. one date column with random daily dates in a period of at least 6 months\n",
    "1. 2 columns containing categorical variables\n",
    "1. 2 columns containing numerical variables\n",
    "\n",
    "You can use Excel's\n",
    "- rand()\n",
    "- randbetween()\n",
    "- norm.inv()\n",
    "- date()\n",
    "- vlookup()\n",
    "\n",
    "functions (or Google Sheets' equivalents) to construct your data set. If you use numpy. you can use the versatile random functions in it. If you wish you can polish your dataset by changing some randomly generated values by hand.\n",
    "\n",
    "Make up a story around your data. In other words: give your data meaning by explaining what your data represents. Being creative in making up your story helps you in improving the joy of doing this exercise! Even better: fabricate some compelling facts in your data that you will extract in your analysis of it.\n",
    "\n",
    "### Step 2: doing the analysis in pandas\n",
    "\n",
    "Conduct an analysis on your data set. Demonstrate your skills in using the following pandas functionality\n",
    "\n",
    "- creating indexes and multiply indices\n",
    "- stacking and unstacking indices\n",
    "- indexing and slicing using loc() and iloc()\n",
    "- using pivot table functionality\n",
    "- using grouping functionality both on categorical variables as on datetime variables\n",
    "- using basic statistical functions as count, mean, average and min/max\n",
    "- plotting (parts of) your data using pandas plotting functionality and seaborn\n",
    "\n",
    "Also, use an alternative SQL approach for one of your analysis steps. Just show that you are capable of leveraging your SQL skills in pandas.\n",
    "\n",
    "Annotate your analysis using markdown cells in your notebook. Briefly introduce each step in your analysis you take and lead your reader through your analysis. Here you have to apply your creativity to make up a sensible, interesting story for your user.\n",
    "\n",
    "Tip: consult the [Python Data Science Handbook](http://bit.ly/2ftE137). It has an excellent chapter on pandas with examples for all techniques you are asked to demonstrate."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
